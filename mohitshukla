# importing libraries 
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, accuracy_score

# Features
X = np.random.rand(100, 1) * 10  
# Target variable with some noise
y = 2.5 * X.squeeze() + np.random.randn(100) * 2  

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Linear Regression
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
y_pred_linear = linear_model.predict(X_test)

# KNN Regression
knn_model = KNeighborsRegressor(n_neighbors=5)
knn_model.fit(X_train, y_train)
y_pred_knn = knn_model.predict(X_test)

# Evaluating the models
print("Linear Regression Mean Squared Error:", mean_squared_error(y_test, y_pred_linear))
print("KNN Regression Mean Squared Error:", mean_squared_error(y_test, y_pred_knn))

# Plotting the results
plt.scatter(X_test, y_test, color='black', label='Actual data')
plt.scatter(X_test, y_pred_linear, color='blue', label='Linear Regression Predictions')
plt.scatter(X_test, y_pred_knn, color='red', label='KNN Regression Predictions')
plt.title('Regression Comparison')
plt.xlabel('Feature')
plt.ylabel('Target')
plt.legend()
plt.show()

# Generating synthetic data for logistic regression

X_class = np.random.rand(100, 2) * 10  # 100 random points in 2D
# Creating a binary target variable
y_class = (X_class[:, 0] + X_class[:, 1] > 10).astype(int)  # Class 1 if sum > 10, else Class 0

# Splitting the data into training and testing sets
X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.2, random_state=42)

# Logistic Regression
logistic_model = LogisticRegression()
logistic_model.fit(X_train_class, y_train_class)
y_pred_class = logistic_model.predict(X_test_class)

# Evaluating the logistic regression model
print("Logistic Regression Accuracy:", accuracy_score(y_test_class, y_pred_class))

# Visualizing the logistic regression decision boundary
plt.figure(figsize=(8, 6))
plt.scatter(X_class[:, 0], X_class[:, 1], c=y_class, cmap='viridis', edgecolor='k')
xlim = plt.xlim()
ylim = plt.ylim()

# Create grid to plot decision boundary
xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 100), np.linspace(ylim[0], ylim[1], 100))
Z = logistic_model.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

plt.contourf(xx, yy, Z, alpha=0.5, cmap='viridis')
plt.title('Logistic Regression Decision Boundary')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.show()
